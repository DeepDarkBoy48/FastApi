from google import genai
from google.genai import types
from pydantic import BaseModel, Field
from typing import List, Optional
import os
import json
from dotenv import load_dotenv
from schemas import (
    AnalysisResult, AnalysisRequest,
    DictionaryResult, LookupRequest,
    WritingResult, WritingRequest, WritingMode,
    ChatRequest,
    QuickLookupResult,
    RapidLookupResult,
    TranslateResult,
    BlogSummaryResult,
    ReviewArticle
)

try:
    load_dotenv()
except Exception as e:
    print(f"Warning: Could not load .env file: {e}")

api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    print("Warning: GEMINI_API_KEY not found in environment. AI features will fail.")
    api_key = "MISSING_API_KEY"

client = genai.Client(api_key=api_key)

# --- Existing Subtitle Logic ---

# --- SmashEnglish Logic ---

# --- Model Configuration Central ---

DEFAULT_MODEL = 'gemini-3-flash-preview'
CHEAP_MODEL = 'gemini-2.5-flash-lite'


def get_analysis_config():
    """å¥å­è¯­æ³•åˆ†æå¡ç‰‡æ¨¡å¼"""
    return DEFAULT_MODEL, 'low'

def get_dictionary_config():
    """è¯¦ç»†è¯å…¸æŸ¥è¯¢æ¨¡å¼"""
    return DEFAULT_MODEL, 'minimal'

def get_writing_config():
    """å†™ä½œæ¶¦è‰²ä¸è¯„åˆ†æ¨¡å¼"""
    return DEFAULT_MODEL, 'low'

def get_chat_config():
    """AI åŠ©æ•™å¯¹è¯æ¨¡å¼"""
    return DEFAULT_MODEL, 'minimal'

def get_lookup_config():
    """ä¸Šä¸‹æ–‡æŸ¥è¯å¡ç‰‡æ¨¡å¼ (å«å¿«é€Ÿä¸æé€Ÿ)"""
    return DEFAULT_MODEL, 'minimal'

def get_translate_config():
    """å…¨æ–‡/å¥å­æé€Ÿç¿»è¯‘æ¨¡å¼"""
    return DEFAULT_MODEL, 'minimal'

def get_crawl_config():
    """ç½‘é¡µæŠ“å–ä¸æ’ç‰ˆæ¨¡å¼ - ä½¿ç”¨æœ€ä¾¿å®œçš„ Lite æ¨¡å‹"""
    return LITE_MODEL, 'minimal'



async def analyze_sentence_service(sentence: str) -> AnalysisResult:
    model, thinking_level = get_analysis_config()
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä½ç²¾é€šè¯­è¨€å­¦å’Œè‹±è¯­æ•™å­¦çš„ä¸“å®¶ AIã€‚è¯·åˆ†æä»¥ä¸‹è‹±è¯­å¥å­ï¼š "{sentence}"ã€‚
    ç›®æ ‡å—ä¼—æ˜¯æ­£åœ¨å­¦ä¹ è‹±è¯­çš„å­¦ç”Ÿï¼Œå› æ­¤åˆ†æéœ€è¦**æ¸…æ™°ã€å‡†ç¡®ä¸”å…·æœ‰æ•™è‚²æ„ä¹‰**ã€‚

    **Language Constraint (è¯­è¨€çº¦æŸ)**:
    - æ‰€æœ‰çš„ `role` (è§’è‰²) å’Œ `partOfSpeech` (è¯æ€§) å­—æ®µ**å¿…é¡»ä¸”åªèƒ½ä½¿ç”¨ç®€ä½“ä¸­æ–‡**ã€‚
    - ä¸¥ç¦è¾“å‡º "Noun", "Verb", "Subject", "Object", "Attribute", "Predicate" ç­‰è‹±æ–‡æœ¯è¯­ã€‚
    - ç¤ºä¾‹è¯æ€§ï¼š "åè¯", "åŠ¨è¯", "å½¢å®¹è¯", "å‰¯è¯", "ä»‹è¯", "ä»£è¯", "è¿è¯", "é™å®šè¯", "åˆ†è¯", "åŠ¨è¯çŸ­è¯­", "ä»‹è¯çŸ­è¯­"ã€‚
    - ç¤ºä¾‹è§’è‰²ï¼š "ä¸»è¯­", "è°“è¯­", "å®¾è¯­", "è¡¨è¯­", "çŠ¶è¯­", "å®šè¯­", "è¡¥è¯­", "å®¾è¯­è¡¥è¶³è¯­", "åŒä½è¯­"ã€‚

    **Processing Steps (Thinking Process):**
    1.  **Grammar Check (çº é”™)**: 
        - ä»”ç»†æ£€æŸ¥å¥å­æ˜¯å¦æœ‰è¯­æ³•é”™è¯¯ã€‚
        - å¦‚æœæœ‰é”™ï¼Œåˆ›å»ºä¸€ä¸ªä¿®æ­£åçš„ç‰ˆæœ¬ã€‚
        - **æ³¨æ„**ï¼šåç»­çš„æ‰€æœ‰åˆ†æï¼ˆchunks, detailedTokens, structureï¼‰å¿…é¡»åŸºäº**ä¿®æ­£å(Corrected)** çš„å¥å­è¿›è¡Œã€‚
        - **Diff Generation**: ç”Ÿæˆ 'changes' æ•°ç»„æ—¶ï¼Œå¿…é¡»æ˜¯ä¸¥æ ¼çš„æ–‡æœ¬å·®å¼‚å¯¹æ¯” (diff)ã€‚
          - 'remove': ä»…åŒ…å«è¢«åˆ é™¤çš„åŸæ–‡ç‰‡æ®µï¼Œ**ç»å¯¹ä¸è¦**åŒ…å« "->" ç¬¦å·æˆ– "change x to y" è¿™æ ·çš„æè¿°ã€‚ä¾‹å¦‚åŸå¥æ˜¯ "i go"ï¼Œä¿®æ­£ä¸º "I go"ï¼Œåˆ™ 'remove' text ä¸º "i"ï¼Œ'add' text ä¸º "I"ã€‚
          - 'add': ä»…åŒ…å«æ–°åŠ å…¥çš„ç‰‡æ®µã€‚
          - 'keep': ä¿æŒä¸å˜çš„éƒ¨åˆ†ã€‚

    2.  **Macro Analysis (å®è§‚ç»“æ„)**:
        - è¯†åˆ«æ ¸å¿ƒå¥å‹ç»“æ„ (Pattern)ï¼Œ**å¿…é¡»åŒ…å«ä¸­æ–‡ç¿»è¯‘**ã€‚æ ¼å¼è¦æ±‚ï¼š"English Pattern (ä¸­æ–‡åç§°)"ã€‚ä¾‹å¦‚ï¼š"S + V + O (ä¸»è°“å®¾)"ã€‚
        - è¯†åˆ«æ ¸å¿ƒæ—¶æ€ (Tense)ï¼Œ**å¿…é¡»åŒ…å«ä¸­æ–‡ç¿»è¯‘**ã€‚æ ¼å¼è¦æ±‚ï¼š"English Tense (ä¸­æ–‡åç§°)"ã€‚ä¾‹å¦‚ï¼š"Present Simple (ä¸€èˆ¬ç°åœ¨æ—¶)"ã€‚

    3.  **Chunking (å¯è§†åŒ–æ„ç¾¤åˆ†å—)**:
        - ç›®æ ‡æ˜¯å±•ç¤ºå¥å­çš„â€œèŠ‚å¥â€å’Œâ€œæ„ç¾¤â€(Sense Groups)ã€‚
        - **åŸåˆ™**ï¼š
          - æ‰€æœ‰çš„ä¿®é¥°è¯­åº”ä¸å…¶ä¸­å¿ƒè¯åœ¨ä¸€èµ·ï¼ˆä¾‹å¦‚ "The very tall man" æ˜¯ä¸€ä¸ªå—ï¼‰ã€‚
          - ä»‹è¯çŸ­è¯­é€šå¸¸ä½œä¸ºä¸€ä¸ªæ•´ä½“ï¼ˆä¾‹å¦‚ "in the morning" æ˜¯ä¸€ä¸ªå—ï¼‰ã€‚
          - è°“è¯­åŠ¨è¯éƒ¨åˆ†åˆå¹¶ï¼ˆä¾‹å¦‚ "have been waiting" æ˜¯ä¸€ä¸ªå—ï¼‰ã€‚
          - ä¸å®šå¼çŸ­è¯­åˆå¹¶ï¼ˆä¾‹å¦‚ "to go home" æ˜¯ä¸€ä¸ªå—ï¼‰ã€‚

    4.  **Detailed Analysis (é€è¯/çŸ­è¯­è¯¦è§£ - æ ¸å¿ƒè¦æ±‚)**:
        - **å…¨è¦†ç›–ä¸æ„ä¹‰åˆ†å—åŸåˆ™ (Comprehensive & Meaningful Chunking)**:
          - ä½ çš„åˆ†æå¿…é¡»è¦†ç›–å¥å­ä¸­çš„**æ‰€æœ‰å†…å®¹**ï¼Œç¡®ä¿æ²¡æœ‰é—æ¼ä»»ä½•è¯­ä¹‰æˆåˆ†ã€‚
          - **ä¸è¦æœºæ¢°åœ°æ‹†åˆ†æ¯ä¸€ä¸ªå•è¯**ã€‚å¦‚æœå‡ ä¸ªè¯å…±åŒæ„æˆä¸€ä¸ªç´§å¯†çš„è¯­ä¹‰å•ä½ï¼ˆå¦‚é™å®šè¯+å½¢å®¹è¯+åè¯ï¼Œæˆ–ä»‹è¯çŸ­è¯­ï¼‰ï¼Œåº”å½“å°†å®ƒä»¬ä½œä¸ºä¸€ä¸ª Token æ•´ä½“åˆ†æã€‚
          - ç¤ºä¾‹ï¼šå¯¹äº "a new language"ï¼Œåº”ä½œä¸ºä¸€ä¸ªæ•´ä½“åˆ†æï¼Œè€Œä¸æ˜¯æ‹†åˆ†ä¸º "a", "new", "language"ã€‚
          - ç¤ºä¾‹ï¼šå¯¹äº "from a proton to the observable universe"ï¼Œåº”æ ¹æ®è¯­ä¹‰èŠ‚å¥æ‹†åˆ†ä¸ºåˆç†çš„å—ï¼Œå¦‚ "from a proton", "to the observable universe"ï¼Œè€Œä¸æ˜¯é€è¯æ‹†åˆ†ã€‚
          - **æ ‡ç‚¹ç¬¦å·**ï¼šé™¤éæ ‡ç‚¹ç¬¦å·åœ¨è¯­æ³•ç»“æ„ä¸Šæœ‰ç‰¹æ®Šæ„ä¹‰ï¼ˆå¦‚ç ´æŠ˜å·ã€åˆ†å·ï¼‰ï¼Œå¦åˆ™é€šå¸¸ä¸éœ€è¦ä½œä¸ºç‹¬ç«‹çš„ Token è¿›è¡Œåˆ†æã€‚
        - **æ ¸å¿ƒåŸåˆ™ - å›ºå®šæ­é…ä¸æ„ç¾¤ä¼˜å…ˆ**ï¼š
          - é‡åˆ°çŸ­è¯­åŠ¨è¯ã€ä¹ è¯­ã€å›ºå®šæ­é…ã€æˆ–ç´§å¯†çš„åè¯çŸ­è¯­æ—¶ï¼Œ**å¿…é¡»**å°†å®ƒä»¬ä½œä¸ºä¸€ä¸ªæ•´ä½“ Tokenã€‚
          - æœ€ç»ˆçš„ `detailedTokens` åˆ—è¡¨æŒ‰é¡ºåºæ‹¼æ¥èµ·æ¥åº”èƒ½ä½“ç°å¥å­çš„å®Œæ•´é€»è¾‘æµã€‚
        - **æ ‡ç­¾è¦æ±‚ (Tags)**ï¼š
          - `partOfSpeech` (è¯æ€§) å’Œ `role` (è§’è‰²) å¿…é¡»ä½¿ç”¨**ç®€ä½“ä¸­æ–‡**ã€‚
        - **è§£é‡Š (Explanation)**ï¼š
          - ä¸è¦åªç»™ä¸€ä¸ªè¯æ€§æ ‡ç­¾ã€‚è¦è§£é‡Šå®ƒåœ¨å¥å­ä¸­çš„**åŠŸèƒ½**å’Œ**è¯­ä¹‰ä½œç”¨**ã€‚
        - **å«ä¹‰ (Meaning)**ï¼šæä¾›è¯¥æ„ç¾¤åœ¨å½“å‰è¯­å¢ƒä¸‹çš„ä¸­æ–‡å«ä¹‰ã€‚

    è¯·è¿”å›ç¬¦åˆ JSON æ ¼å¼çš„æ•°æ®ã€‚
    """

    try:
        response = await client.aio.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=AnalysisResult,
                thinking_config=types.ThinkingConfig(
                    include_thoughts=True,
                    thinking_level=thinking_level
                ) if thinking_level != 'minimal' else types.ThinkingConfig(thinking_level='minimal'),
            )
        )
        
        if not response.parsed:
             raise ValueError("Empty response from Gemini")
             
        result = response.parsed
        # Match frontend logic: use corrected sentence if available
        if result.correction:
            result.englishSentence = result.correction.corrected
        else:
            result.englishSentence = sentence
            
        return result
    except Exception as e:
        print(f"Gemini API Error: {e}")
        raise Exception("æ— æ³•åˆ†æè¯¥å¥å­ã€‚è¯·æ£€æŸ¥ç½‘ç»œæˆ– API Key è®¾ç½®ã€‚")


async def lookup_word_service(word: str) -> DictionaryResult:
    model, thinking_level = get_dictionary_config()

    prompt = f"""
    Act as a professional learner's dictionary specifically tailored for students preparing for **IELTS, TOEFL, and CET-6**.
    User Look-up Query: "{word}".
    
    **STEP 1: Normalization & Generalization (CRITICAL)**
    1. Analyze the user's input. Is it a specific instance of a phrasal verb or collocation with specific pronouns?
    2. If yes, convert it to the **Canonical Form** (Headword).
       - Input: "pop us back" -> Output: "pop sth back"
       - Input: "made up my mind" -> Output: "make up one's mind"
    
    **STEP 2: Filtering & Content Generation**
    1. **Target Audience**: Students preparing for exams (IELTS, TOEFL, CET-6) and daily communication.
    2. **Filtering Rule**: 
       - OMIT rare, archaic, obsolete, or highly technical scientific definitions unless the word itself is technical.
       - Focus ONLY on the most common 3-4 meanings used in modern English and exams.
    3. **COCA Frequency per Part of Speech**:
       - For each part of speech (e.g. Noun vs Verb), estimate its specific COCA frequency rank.
       - Example: "address" might be "Rank 1029" as a Noun, but "Rank 1816" as a Verb.
       - Provide a concise string like "Rank 1029" or "Top 2000".

    **STEP 3: Structure**
    - Definitions: Provide a clear and concise meaning in **Simplified Chinese**. 
    - Explanation: Provide a detailed explanation of the usage, nuances, or grammatical context **EXCLUSIVELY in Simplified Chinese**. (DO NOT provide English explanations).
    - Examples: Must be natural, modern, and relevant to exam contexts or daily life.
    - Example Translation: Provide a natural translation of the example in **Simplified Chinese**.
    
    **STEP 4: Collocations & Fixed Phrases**
    - Identify 3-5 high-frequency collocations, idioms, or fixed phrases containing this word.
    - Prioritize phrases useful for IELTS/TOEFL writing or speaking.
    - Provide the meaning in **Simplified Chinese** and a sentence example with its Chinese translation for each.

    Structure the response by Part of Speech (POS).
    Return strictly JSON.
    """

    try:
        response = await client.aio.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=DictionaryResult,
                thinking_config=types.ThinkingConfig(
                    include_thoughts=True,
                    thinking_level=thinking_level
                ) if thinking_level != 'minimal' else types.ThinkingConfig(thinking_level='minimal'),
            )
        )
        
        if not response.parsed:
             raise ValueError("Empty response from Gemini")
        
        return response.parsed
    except Exception as e:
        print(f"Dictionary API Error: {e}")
        raise Exception("æ— æ³•æŸ¥è¯¢è¯¥å•è¯ï¼Œè¯·é‡è¯•ã€‚")


async def evaluate_writing_service(text: str, mode: WritingMode) -> WritingResult:
    model, thinking_level = get_writing_config()

    mode_instructions = """
    **MODE: BASIC CORRECTION (åŸºç¡€çº é”™)**
    - Target: General accuracy.
    - Task: Focus STRICTLY on correcting grammar, spelling, punctuation, and serious awkwardness.
    - Do NOT change style, tone, or vocabulary unless it is incorrect.
    - Keep the output very close to the original, only fixing errors.
    """

    prompt = f"""
    Act as a professional English Writing Coach and Editor.
    
    {mode_instructions}

    **Task**:
    Analyze the user's text and reconstruct it into the *Improved Version*.
    
    **Target Standard (CRITICAL)**:
    - **US High School Student Level**: The improved text should flow naturally like a native US high school student's writing. 
    - **Beyond Basic Grammar**: Do not just fix grammatical errors. Improve sentence structure, vocabulary choice, and flow to make it sound idiomatic and cohesive.
    - **Maintain Meaning**: Improve the expression but keep the original meaning and intent.

    **Input Text**: "{text}"

    **Output Logic**:
    1. **Overall Comment**: Provide a comprehensive summary of the writing (in Simplified Chinese). Mention the good points and the main areas for improvement (e.g., "Sentence variety", "Vocabulary depth", "Logic flow").
    2. **Segments**:
       - Iterate through the improved text.
       - If a part of the text is unchanged, mark it as 'unchanged'.
       - If you changed, added, or removed something, create a segment of type 'change'.
         - 'text': The NEW/IMPROVED text.
         - 'original': The ORIGINAL text that was replaced (or empty string if added).
         - 'reason': A specific, educational explanation in **Simplified Chinese**. Explain WHY the change improves the text (e.g., "Change 'happy' to 'elated' for better vocabulary", "Combine sentences for better flow").
         - 'category': One of 'grammar', 'vocabulary', 'style', 'punctuation', 'collocation', 'flow'.
    
    **CRITICAL - PARAGRAPH PRESERVATION**: 
    - You MUST preserve all paragraph breaks and newlines (\\n) from the original text exactly as they are.
    - When you encounter a newline in the original text, return it as a separate segment: {{ "text": "\\n", "type": "unchanged" }}.
    - Do NOT merge paragraphs.

    **Example**:
    Original: "I go store today. It big."
    Improved: "I went to the store today. It was huge."
    Segments:
    [
      {{ "text": "I ", "type": "unchanged" }},
      {{ "text": "went", "original": "go", "type": "change", "reason": "æ—¶æ€ä¿®æ­£ï¼šåº”ä½¿ç”¨è¿‡å»æ—¶", "category": "grammar" }},
      {{ "text": " to the ", "original": "", "type": "change", "reason": "ç¼ºå¤±ä»‹è¯å’Œå† è¯", "category": "grammar" }},
      {{ "text": "store today. It was ", "type": "unchanged" }},
      {{ "text": "huge", "original": "big", "type": "change", "reason": "è¯æ±‡å‡çº§ï¼š'huge' æ¯” 'big' æ›´å…·ä½“", "category": "vocabulary" }},
      {{ "text": ".", "type": "unchanged" }}
    ]

    Return strictly JSON.
    """
    
    # Define a partial schema for response to match WritingResult structure but without 'mode' which we set manually
    class WritingResponseSchema(BaseModel):
        generalFeedback: str
        overall_comment: str
        segments: List[WritingResult.model_fields['segments'].annotation]

    try:
        response = await client.aio.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=WritingResult, # Using the full WritingResult schema, hoping Gemini fills 'mode' or we override it
                thinking_config=types.ThinkingConfig(
                    include_thoughts=True,
                    thinking_level=thinking_level
                ) if thinking_level != 'minimal' else types.ThinkingConfig(thinking_level='minimal'),
            )
        )

        if not response.parsed:
            raise ValueError("Empty response")
            
        result = response.parsed
        # Ensure mode matches request
        result.mode = mode
        return result

    except Exception as e:
        print(f"Writing Evaluation API Error: {e}")
        raise Exception("å†™ä½œåˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åå†è¯•ã€‚")


async def chat_service(request: ChatRequest) -> str:
    model, thinking_level = get_chat_config()
    context_instruction = ""
    if request.contextType == 'sentence':
         context_instruction = f'**å½“å‰æ­£åœ¨åˆ†æçš„å¥å­**: "{request.contextContent or "ç”¨æˆ·æš‚æœªè¾“å…¥å¥å­"}"ã€‚'
    elif request.contextType == 'word':
         context_instruction = f'**å½“å‰æ­£åœ¨æŸ¥è¯¢çš„å•è¯/è¯ç»„**: "{request.contextContent or "ç”¨æˆ·æš‚æœªæŸ¥è¯¢å•è¯"}"ã€‚'
    elif request.contextType == 'writing':
         context_instruction = f'**å½“å‰æ­£åœ¨æ¶¦è‰²çš„æ–‡ç« **: "{request.contextContent or "ç”¨æˆ·æš‚æœªè¾“å…¥æ–‡ç« "}"ã€‚'

    system_instruction = f"""
        ä½ æ˜¯ä¸€ä¸ªçƒ­æƒ…ã€ä¸“ä¸šçš„è‹±è¯­å­¦ä¹ åŠ©æ•™ã€‚ä½ ç°åœ¨æ‹¥æœ‰è®¿é—® **Google æœç´¢** çš„èƒ½åŠ›ï¼Œå¯ä»¥æä¾›æœ€å‰æ²¿ã€æœ€åœ°é“çš„è‹±è¯­ç”¨æ³•å‚è€ƒã€‚
        
        {context_instruction}
        
        **ä½ çš„ä»»åŠ¡**ï¼š
        1. è§£ç­”ç”¨æˆ·å…³äºè‹±è¯­è¯­æ³•ã€å•è¯ç”¨æ³•ã€å¥å­ç»“æ„æˆ–è¯æ±‡è¾¨æçš„é—®é¢˜ã€‚
        2. **åˆ©ç”¨å®æ—¶æœç´¢**ï¼šå¦‚æœç”¨æˆ·è¯¢é—®çš„æ˜¯æœ€æ–°çš„ç½‘ç»œæµè¡Œè¯­ã€ä¿šè¯­ã€æˆ–è€…æ¶‰åŠç‰¹å®šæ–‡åŒ–/æ—¶äº‹èƒŒæ™¯çš„è‹±è¯­è¡¨è¾¾ï¼Œè¯·åŠ¡å¿…ä½¿ç”¨æœç´¢åŠŸèƒ½æ¥è·å–æœ€å‡†ç¡®ã€æœ€æ–°çš„è§£é‡Šå’Œå®ä¾‹ã€‚
        3. **æä¾›åœ°é“ä¾‹å¥**ï¼šåœ¨è§£é‡Šè¯æ±‡æ—¶ï¼Œå¯ä»¥ä¸»åŠ¨é€šè¿‡æœç´¢ä»æƒå¨åª’ä½“ï¼ˆå¦‚ BBC, NYT, The Economistï¼‰ä¸­æå–çœŸå®ä¾‹å¥ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£è¯¥è¯åœ¨ç°ä»£è‹±è¯­ä¸­çš„å®é™…åº”ç”¨ã€‚
        4. **å¼•ç”¨æ¥æº**ï¼šå¦‚æœä½ çš„å›ç­”å¼•ç”¨äº†æœç´¢ç»“æœï¼Œè¯·æ ¹æ®æœç´¢å…ƒæ•°æ®æä¾›æ¸…æ™°çš„æ¥æºé“¾æ¥ï¼ˆæ ¼å¼å¦‚ [æ ‡é¢˜](é“¾æ¥)ï¼‰ï¼Œå¢åŠ å›ç­”çš„å¯ä¿¡åº¦ã€‚
        5. **å§‹ç»ˆä½¿ç”¨ä¸­æ–‡**å›ç­”ã€‚
        6. ä½¿ç”¨ **Markdown** æ ¼å¼æ¥ç¾åŒ–ä½ çš„å›ç­”ï¼Œä½¿å…¶æ¸…æ™°æ˜“è¯»ï¼š
           - ä½¿ç”¨ **åŠ ç²—** æ¥å¼ºè°ƒé‡ç‚¹å•è¯æˆ–è¯­æ³•æœ¯è¯­ã€‚
           - ä½¿ç”¨åˆ—è¡¨ï¼ˆ1. æˆ– -ï¼‰æ¥åˆ†ç‚¹è§£é‡Šã€‚
           - é€‚å½“åˆ†æ®µã€‚
        7. è¯­æ°”è¦é¼“åŠ±ã€ç§¯æï¼Œåƒä¸€ä½è€å¿ƒçš„è€å¸ˆã€‚
        8. **ç‰¹æ®ŠæŒ‡ä»¤**ï¼šå¦‚æœç”¨æˆ·è¯¢é—®ç±»ä¼¼ "pop us back" è¿™æ ·çš„çŸ­è¯­ï¼Œè¯·è§£é‡Šè¿™æ˜¯ä¸€ç§å£è¯­è¡¨è¾¾ï¼Œæ ¸å¿ƒæ˜¯çŸ­è¯­åŠ¨è¯ "pop back" (è¿…é€Ÿå›å»)ï¼Œ"us" æ˜¯å®¾è¯­ã€‚
    """
    
    # Reconstruct history for Gemini
    # Gemini python SDK expects a slightly different history format if using chat.sendMessage
    # But here we might just do a single turn generation with history context if we want to be stateless, 
    # OR use the chat session. Given FastAPI is stateless, we should probably pass the history.
    # However, the `google.genai` SDK `chats.create` creates a session. 
    # We can manually construct the `contents` list from history + new message.
    
    contents = []
    for msg in request.history:
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå°† 'assistant' è½¬æ¢ä¸º Gemini æœŸæœ›çš„ 'model'
        role = 'model' if msg.role == 'assistant' else msg.role
        contents.append(types.Content(role=role, parts=[types.Part(text=msg.content)]))
    
    # Add user's new message
    contents.append(types.Content(role='user', parts=[types.Part(text=request.userMessage)]))

    try:
        response = await client.aio.models.generate_content(
            model=model,
            contents=contents,
            config=types.GenerateContentConfig(
                system_instruction=system_instruction,
                tools=[types.Tool(google_search=types.GoogleSearch())],
                thinking_config=types.ThinkingConfig(
                    include_thoughts=True,
                    thinking_level=thinking_level
                ) if thinking_level != 'minimal' else types.ThinkingConfig(thinking_level='minimal'),
            )
        )
        return response.text
    except Exception as e:
        print(f"Chat API Error: {e}")
        raise Exception("èŠå¤©æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚")


async def quick_lookup_service(word: str, context: str) -> QuickLookupResult:
    """å¿«é€Ÿä¸Šä¸‹æ–‡æŸ¥è¯æœåŠ¡ - ç»™å‡ºå•è¯åœ¨ä¸Šä¸‹æ–‡ä¸­çš„é‡Šä¹‰å’Œè§£é‡Š"""
    model, thinking_level = get_lookup_config()

    prompt = f"""
    ä½ æ˜¯ä¸€ä½è‹±è¯­æ•™å­¦ä¸“å®¶ã€‚è¯·åˆ†æå•è¯ "{word}" åœ¨ä»¥ä¸‹å¥å­ä¸Šä¸‹æ–‡ä¸­çš„å…·ä½“å«ä¹‰ã€è¯æ€§ã€è¯­æ³•æˆåˆ†å’Œç”¨æ³•ï¼š
    
    **å¥å­ä¸Šä¸‹æ–‡**: "{context}"
    
    **ä»»åŠ¡è¦æ±‚**:
    1. **contextMeaning**: ç»™å‡ºè¿™ä¸ªè¯åœ¨å½“å‰ä¸Šä¸‹æ–‡ä¸­çš„**å…·ä½“ä¸­æ–‡é‡Šä¹‰**ï¼ˆç®€æ´ï¼Œ1-2ä¸ªè¯ï¼‰ã€‚
    2. **partOfSpeech**: ç»™å‡ºè¿™ä¸ªè¯åœ¨å½“å‰è¯­å¢ƒä¸‹çš„**ç²¾å‡†è¯æ€§ç¼©å†™**ï¼ˆå¦‚ï¼šåŠç‰©åŠ¨è¯ vt., ä¸åŠç‰©åŠ¨è¯ vi., åè¯ n., å½¢å®¹è¯ adj., å‰¯è¯ adv., ä»‹è¯ prep., è¿è¯ conj. ç­‰ï¼‰ã€‚
    3. **grammarRole**: ç»™å‡ºè¿™ä¸ªè¯åœ¨å¥å­ä¸­çš„**è¯­æ³•æˆåˆ†**ï¼ˆå¦‚ï¼šä¸»è¯­ã€è°“è¯­ã€å®¾è¯­ã€å®šè¯­ã€çŠ¶è¯­ã€è¡¨è¯­ã€å®¾è¡¥ã€åŒä½è¯­ç­‰ï¼‰æˆ–**å›ºå®šæ­é…/çŸ­è¯­**ã€‚
    4. **explanation**: ç»“åˆè¯­å¢ƒè¿›è¡Œåœ°é“ç¿»è¯‘ä¸æ·±åº¦è§£æã€‚
       - **å…¨æ–‡ç¿»è¯‘(å¿…é¡»)**: é¦–å…ˆç»™å‡ºæ•´ä¸ªåŸå¥çš„åœ°é“ã€å£è¯­åŒ–çš„ä¸­æ–‡ç¿»è¯‘ã€‚
       - **ç”¨æ³•è§£æ**: ç®€è¦è§£é‡Šå•è¯ä¸ºä»€ä¹ˆæ˜¯è¿™ä¸ªæ„æ€åŠå…¶åœ¨å¥ä¸­çš„å…·ä½“ç”¨æ³•ç»†èŠ‚ï¼ˆå¦‚ï¼šæ˜¯å¹¶åˆ—ç»“æ„å—ï¼ŸæŒ‡ä»£ä»€ä¹ˆï¼Ÿï¼‰ã€‚
       - å¦‚æœæ¶‰åŠå›ºå®šæ­é…ï¼ˆå¦‚ "upload...to..."ï¼‰ï¼Œè¯·åŠ¡å¿…æŒ‡å‡ºæ¥ã€‚
       - ç»“åˆä¸Šä¸‹æ–‡èƒŒæ™¯ï¼Œè¯´æ˜è¯¥è¯ä¼ è¾¾çš„è¯­æ°”æˆ–å…·ä½“æŒ‡ä»£çš„å¯¹è±¡ã€‚
    5. **otherMeanings**: æä¾›è¯¥å•è¯çš„**å…¶ä»–å¸¸è§ä¸”é«˜é¢‘**çš„é‡Šä¹‰ã€‚
       - **è¿‡æ»¤è§„åˆ™**: ä¸¥ç¦æä¾›ç”Ÿåƒ»ã€å¤åƒ»ã€è¿‡äºä¸“ä¸šæˆ–ç½•è§çš„é‡Šä¹‰ã€‚åªä¿ç•™åœ¨ä¸­é«˜è€ƒã€é›…æ€ã€æ‰˜ç¦æˆ–æ—¥å¸¸å£è¯­ä¸­å¸¸è§çš„ 2-3 ä¸ªå…¶ä»–æ„æ€ã€‚
       - æ¯ä¸ªæ„æ€éœ€åŒ…å« `meaning` (ä¸­æ–‡é‡Šä¹‰)ã€`partOfSpeech` (è¯æ€§) ä»¥åŠä¸€ä¸ªç®€çŸ­çš„è‹±æ–‡ä¾‹å¥ `example`ã€‚
    
    **è¾“å‡ºè¯­è¨€**: å…¨éƒ¨ä½¿ç”¨ç®€ä½“ä¸­æ–‡ï¼ˆé‡Šä¹‰å’Œè§£é‡Šéƒ¨åˆ†ï¼‰ã€‚
    **è¾“å‡ºæ ¼å¼**: ä¸¥æ ¼ JSONã€‚
    
    ç¤ºä¾‹è¾“å‡º:
    {{
      "word": "footage",
      "contextMeaning": "ç´ æï¼Œè§†é¢‘å‰ªè¾‘",
      "partOfSpeech": "n.",
      "grammarRole": "å®¾è¯­ (ä¸ upload æ„æˆåŠ¨å®¾çŸ­è¯­)",
      "explanation": "ã€å¥å­ç¿»è¯‘ã€‘åœ¨è¿™ä¸ªå¥å­ä¸­æ„ä¸ºï¼šâ€˜å°†ä½ çš„è§†é¢‘ç´ æä¸Šä¼ åˆ° YouTubeâ€™ã€‚\\n\\nã€è§£æã€‘è¿™é‡Œ 'footage' æŒ‡çš„æ˜¯æ‹æ‘„å¥½çš„è§†é¢‘ç´ æã€‚å›ºå®šæ­é… 'upload your footage to YouTube' å±•ç¤ºäº†å…¶åœ¨æ•°å­—åª’ä½“è¯­å¢ƒä¸‹çš„å…¸å‹ç”¨æ³•ï¼Œç‰¹æŒ‡å·²å®Œæˆæ‹æ‘„ã€å‡†å¤‡è¿›è¡ŒåæœŸåˆ¶ä½œæˆ–ç›´æ¥ä¸Šä¼ çš„è§†é¢‘å†…å®¹ã€‚",
      "otherMeanings": [
        {{ "meaning": "è‹±å°ºé•¿åº¦", "partOfSpeech": "n.", "example": "The room has a lot of square footage." }}
      ]
    }}

    """


    try:
        response = await client.aio.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=QuickLookupResult,
                thinking_config=types.ThinkingConfig(thinking_level=thinking_level),
            )
        )
        
        if not response.parsed:
            raise ValueError("Empty response from Gemini")
        
        result = response.parsed
        result.word = word  # Ensure correct word is returned
        return result
    except Exception as e:
        print(f"Quick Lookup API Error: {e}")
        raise Exception("å¿«é€ŸæŸ¥è¯å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚")


async def rapid_lookup_service(word: str, context: str) -> RapidLookupResult:
    """æé€ŸæŸ¥è¯æœåŠ¡ - æè‡´ç®€çŸ­çš„ Prompt ä»¥æé«˜å“åº”é€Ÿåº¦"""
    model, thinking_level = get_lookup_config()
    
    # ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹æˆ–é…ç½®
    # å¼ºåˆ¶ä¸ä½¿ç”¨ thinking ä»¥å‡å°‘å»¶è¿Ÿ
    prompt = f"Word: {word}\nContext: {context}\nOutput: Concise Chinese meaning (m) and POS (p) in JSON."

    try:
        response = await client.aio.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=RapidLookupResult,
                # å°½é‡ç¦ç”¨æ‰€æœ‰é¢å¤–å¼€é”€
                thinking_config=types.ThinkingConfig(thinking_level=thinking_level),
            )
        )
        
        if not response.parsed:
            raise ValueError("Empty response")
        
        return response.parsed
    except Exception as e:
        print(f"Rapid Lookup API Error: {e}")
        # è¿”å›ä¸€ä¸ªé™çº§çš„å“åº”
        return RapidLookupResult(m="æŸ¥è¯¢å¤±è´¥", p="?")

async def translate_service(text: str) -> TranslateResult:
    """æé€Ÿç¿»è¯‘æœåŠ¡ - å°†è‹±æ–‡å¥å­ç¿»è¯‘ä¸ºåœ°é“çš„ä¸­æ–‡"""
    model, thinking_level = get_translate_config()

    system_instruction = """
    ä½ æ˜¯ä¸€ä¸ªæé€Ÿç¿»è¯‘åŠ©æ‰‹ã€‚
    ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·è¾“å…¥çš„è‹±æ–‡å¥å­ç¿»è¯‘æˆåœ°é“ã€è‡ªç„¶ã€ç®€æ´çš„ç®€ä½“ä¸­æ–‡ã€‚
    åªè¿”å›ç¿»è¯‘ç»“æœï¼Œä¸è¦æœ‰ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–è¯´æ˜ã€‚
    """

    try:
        response = await client.aio.models.generate_content(
            model=model,
            contents=text,
            config=types.GenerateContentConfig(
                system_instruction=system_instruction,
                thinking_config=types.ThinkingConfig(thinking_level=thinking_level),
            )
        )
        
        if not response.text:
            raise ValueError("Empty response from Gemini")
        
        return TranslateResult(translation=response.text.strip())
    except Exception as e:
        print(f"Translate API Error: {e}")
async def generate_daily_summary_service(words: List[dict]) -> BlogSummaryResult:
    """ç”¨ AI ç»“åˆ Google æœç´¢å¯¹å½“å¤©çš„å•è¯åŠæ¥æºé“¾æ¥è¿›è¡Œä¸²è”æ€»ç»“ (ç»“æ„åŒ–è¾“å‡º)"""
    model = DEFAULT_MODEL
    
    # æ„å»ºå•è¯å’Œ URL ä¿¡æ¯å­—ç¬¦ä¸²
    words_info = ""
    for w in words:
        data = w['data']
        meaning = data.get('contextMeaning') or data.get('m') or 'æœªçŸ¥'
        pos = data.get('partOfSpeech') or ''
        role = data.get('grammarRole') or ''
        exp = data.get('explanation') or ''
        others = data.get('otherMeanings') or []
        
        word_meta = {
            "word": w['word'],
            "contextMeaning": meaning,
            "partOfSpeech": pos,
            "grammarRole": role,
            "explanation": exp,
            "otherMeanings": others,
            "context": w['context'],
            "url": w.get('url') or data.get('url', '')
        }
        words_info += f"- {json.dumps(word_meta, ensure_ascii=False)}\n"
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä½å¯¹æ’ç‰ˆç¾å­¦æœ‰æè‡´è¿½æ±‚çš„è‹±è¯­å­¦ä¹ æ’­å®¢å¯¼æ¼”ã€‚
    ä»¥ä¸‹æ˜¯ç”¨æˆ·ä»Šå¤©å­¦ä¹ å¹¶æ”¶è—çš„è‹±è¯­å•è¯ï¼Œä»¥åŠå®ƒä»¬è¯¦ç»†çš„èƒŒæ™¯å…ƒæ•°æ® (JSON æ ¼å¼)ï¼š
    
    {words_info}
    
    **ä½ çš„ç›®æ ‡**:
    åˆ›ä½œä¸€æœŸåä¸ºâ€œè‹±è¯­æ²‰æµ¸è§†ç•Œâ€çš„**è®¿è°ˆå®å½•**ã€‚ä½ éœ€è¦å…ˆå±•ç¤ºæå…·è®¾è®¡æ„Ÿçš„å…¨è‹±æ–‡å¯¹è¯ï¼Œå†æä¾›æ’ç‰ˆä¼˜é›…çš„ä¸­æ–‡å¯¹ç…§ã€‚
    
    **æ ¸å¿ƒè¦æ±‚**:
    1. **åˆ©ç”¨ Google æœç´¢ (CRITICAL)**: 
       - å¿…é¡»æœç´¢ URLï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œè®©å˜‰å®¾ (Guest) çš„è‹±æ–‡å†…å®¹å……æ»¡åŸºäºçœŸå®èƒŒæ™¯çš„æ·±åº¦å’Œè¶£å‘³ã€‚
    2. **Catchy Title**: 
       - [Emoji] + [ä¸­æ–‡ä¸»é¢˜æ ‡é¢˜]ã€‚Emoji æ ¹æ®å†…å®¹åŠ¨æ€è‡ªé€‰ï¼Œä¸¥ç¦æœºæ¢°ä½¿ç”¨æ’­å®¢å›¾æ ‡ã€‚æ ‡é¢˜ä»…ä¸­æ–‡ã€‚
    3. **Concise Prologue**: 80-120 å­—çš„ä¸­æ–‡å¼€åœºç™½ã€‚
    4. **Transcript Layout (æ’ç‰ˆç¾å­¦ - é‡ç‚¹)**: 
       - **åŒºåˆ†è®¿è°ˆéƒ¨åˆ†**: ä½¿ç”¨ `### ğŸ™ï¸ English Transcript` å’Œ `### ğŸ“„ ä¸­æ–‡è®¿è°ˆè®°å½•` ä½œä¸ºäºŒçº§æ ‡é¢˜ï¼Œä¸”ä¸¤è€…ä¹‹é—´ä½¿ç”¨ `---` åˆ†éš”çº¿ã€‚
       - **è§’è‰²è§†è§‰åŒºåˆ† (éä¾µå…¥æ€§)**: 
         - **Host:** è¡¨ç°ä¸ºå¸¸è§„ç²—ä½“å¼€å¤´ã€‚ (ä¾‹å¦‚: **Host:** Hello there...)
         - **Guest:** è¡¨ç°ä¸ºç²—ä½“å¼€å¤´å¹¶**åŠ ä¸Š Blockquote å¼•ç”¨ç¬¦å·**ã€‚ (ä¾‹å¦‚: > **Guest:** Well, in my opinion...) 
         - **ç†ç”±**: å¼•ç”¨ç¬¦å·åœ¨ MD ä¸­é€šå¸¸ä¼šäº§ç”Ÿè‰²å½©ä¾§è¾¹æ¡ï¼Œèƒ½å®Œç¾åŒºåˆ†å¯¹è¯åŒæ–¹ä¸”ä¸å¤±ä¼˜é›…ã€‚
       - **é‡ç‚¹æ ‡æ³¨**: ä»…åœ¨è‹±æ–‡å®å½•ä¸­ä½¿ç”¨ **ç²—ä½“** æ ‡æ³¨æ”¶è—çš„è¯æ±‡ã€‚
    5. **English Interview**: 
       - Host å’Œ Guest å…¨ç¨‹ä½¿ç”¨æåº¦å£è¯­åŒ–ã€ç”ŸåŠ¨çš„è‹±æ–‡ã€‚å¯¹è¯è¦ä¸€æ°”å‘µæˆã€‚
    6. **Chinese Translation**: 
       - åœ¨åˆ†éš”çº¿åæä¾›å®Œæ•´çš„ç¿»è¯‘ã€‚ç¿»è¯‘ç‰ˆä¹Ÿè¦éµå¾ªç›¸åŒçš„ **Host** å’Œ > **Guest** æ’ç‰ˆè§„åˆ™ã€‚
    
    è¯·è¾“å‡ºç®€ä½“ä¸­æ–‡ä½œä¸ºä¸»æ§è¯­è¨€ã€‚
    """

    try:
        response = await client.aio.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                tools=[types.Tool(google_search=types.GoogleSearch())],
                response_mime_type="application/json",
                response_schema=BlogSummaryResult,
                thinking_config=types.ThinkingConfig(thinking_level='low'), 
            )
        )
        if response.parsed:
            return response.parsed
        
        # Fallback if parsing fails
        return BlogSummaryResult(
            title="ä»Šæ—¥å­¦ä¹ å›é¡¾ ğŸ“–",
            prologue="è¿™æ˜¯ä¸€ä»½åŸºäºä½ ä»Šæ—¥å­¦ä¹ è¯æ±‡è‡ªåŠ¨ç”Ÿæˆçš„æ€»ç»“ã€‚",
            content=response.text.strip() if response.text else "ä»Šå¤©å­¦ä¹ äº†è¿™äº›è¯ï¼Œè¦ç»§ç»­åŠ æ²¹å“¦ï¼"
        )
    except Exception as e:
        print(f"Summary Generation Error: {e}")
        return BlogSummaryResult(
            title="ç”Ÿæˆå¤±è´¥",
            prologue="AI åœ¨å°è¯•æ·±å…¥äº†è§£è¿™äº›å•è¯èƒŒæ™¯æ—¶é‡åˆ°äº†ä¸€äº›æŒ‘æˆ˜ã€‚",
            content=f"é”™è¯¯è¯¦æƒ…: {str(e)}\n\n{words_info}"
        )

async def generate_review_article_service(words: List[dict]) -> ReviewArticle:
    """ä¸º FSRS å¤ä¹ æ¨¡å¼ç”Ÿæˆæ¯æ—¥è¶£å‘³æ–‡ç«  (æ’­å®¢ã€è¾©è®ºã€é‡‡è®¿ã€åšå®¢ç­‰)"""
    model = DEFAULT_MODEL
    
    # éšæœºé€‰æ‹©æ–‡ç« ç±»å‹
    import random
    types_list = [
        ("podcast", "æ’­å®¢"), 
        ("interview", "é‡‡è®¿"), 
        ("debate", "è¾©è®º"), 
        ("blog", "æ·±åº¦åšå®¢"),
        ("news", "æ–°é—»ç‰¹å†™")
    ]
    article_type_code, article_type_name = random.choice(types_list)

    # æ„å»ºå•è¯å…ƒæ•°æ®
    words_info = ""
    for w in words:
        data = json.loads(w['data']) if isinstance(w['data'], str) else w['data']
        meaning = data.get('contextMeaning') or data.get('m') or 'æœªçŸ¥'
        pos = data.get('partOfSpeech') or ''
        role = data.get('grammarRole') or ''
        exp = data.get('explanation') or ''
        others = data.get('otherMeanings') or []
        
        word_meta = {
            "word": w['word'],
            "contextMeaning": meaning,
            "partOfSpeech": pos,
            "grammarRole": role,
            "explanation": exp,
            "otherMeanings": others,
            "context": w['context']
        }
        words_info += f"- {json.dumps(word_meta, ensure_ascii=False)}\n"

    prompt = f"""
    ä½ æ˜¯ä¸€ä½å¤©æ‰å†…å®¹åˆ›ä½œè€…ï¼Œæ“…é•¿ç¼–å†™æå…·å¸å¼•åŠ›çš„è‹±è¯­å­¦ä¹ å†…å®¹ã€‚
    ä»Šå¤©ä½ éœ€è¦æ ¹æ®ç”¨æˆ·å¤ä¹ çš„ 30 ä¸ªå•è¯ï¼Œç¼–å†™ä¸€ç¯‡æ–‡ç« ï¼Œå½¢å¼ä¸ºï¼š**{article_type_name}**ã€‚

    **å¾…åŒ…å«çš„å•è¯åŠå…¶è¯¦ç»†èƒŒæ™¯ (JSON æ ¼å¼)**:
    {words_info}

    **æ ¸å¿ƒä»»åŠ¡**:
    1. **åˆ›ä½œå†…å®¹**: ç¼–å†™ä¸€ç¯‡ç”ŸåŠ¨æœ‰è¶£çš„è‹±æ–‡æ–‡ç« ï¼ˆåŒ…å«å¯¹åº”çš„ä¸­æ–‡ç¿»è¯‘ï¼‰ã€‚
    2. **è‡ªç„¶åµŒå…¥**: ç»å¯¹ä¸è¦ç”Ÿç¡¬åœ°ç½—åˆ—å•è¯ï¼Œè¦è®©è¿™ 30 ä¸ªå•è¯è‡ªç„¶åœ°å‡ºç°åœ¨æƒ…å¢ƒä¸­ã€‚
    3. **åˆ©ç”¨èƒŒæ™¯**: å‚è€ƒæä¾›çš„ `Context` (è¯­å¢ƒ)ï¼Œå¦‚æœæŸä¸ªè¯æ˜¯åœ¨ YouTube è§†é¢‘ä¸­å‡ºç°çš„ï¼Œå¯ä»¥åœ¨æ–‡ä¸­æåŠç›¸å…³çš„èƒŒæ™¯è¯é¢˜ã€‚
    4. **åŒè¯­æ ¼å¼**: ä½¿ç”¨ Markdown ç¼–å†™ã€‚å…ˆå±•ç¤ºå®Œæ•´çš„è‹±æ–‡ç‰ˆï¼Œç„¶åæ˜¯ä¸­æ–‡ç¿»è¯‘ç‰ˆã€‚
    5. **é‡ç‚¹çªå‡º**: åœ¨è‹±æ–‡ç‰ˆä¸­ï¼Œå°†è¿™ 30 ä¸ªå•è¯ç”¨ **åŠ ç²—** æ ‡æ³¨ã€‚

    **è¾“å‡ºæ ¼å¼**: ä¸¥æ ¼ JSONï¼ŒåŒ¹é… Schemaã€‚
    `title`: ç»™æ–‡ç« èµ·ä¸€ä¸ªå¸å¼•äººçš„åŒè¯­æ ‡é¢˜ã€‚
    `content`: Markdown æ ¼å¼çš„æ–‡ç« æ­£æ–‡ã€‚
    `article_type`: å›ºå®šä¸º "{article_type_code}"ã€‚

    è¯·æ³¨æ„ï¼šæ–‡ç« è¦æœ‰æ·±åº¦ï¼Œä¸è¦å¤ªå¹¼ç¨šã€‚å¦‚æœæ˜¯è¾©è®ºï¼Œè¯·å±•ç°ä¸¤ç§ä¸åŒçš„è§‚ç‚¹ï¼›å¦‚æœæ˜¯æ’­å®¢ï¼Œè¯·å±•ç°ä¸¤ä½ä¸»æŒäººä¹‹é—´çš„ç¢°æ’ã€‚
    """

    try:
        response = await client.aio.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=ReviewArticle,
                thinking_config=types.ThinkingConfig(thinking_level='low'), 
            )
        )
        if response.parsed:
            return response.parsed
        
        return ReviewArticle(
            title="ä»Šæ—¥å•è¯å¤ä¹ ",
            content="æ–‡ç« ç”Ÿæˆå¤±è´¥ï¼Œä½†ä½ å¯ä»¥ç›´æ¥åœ¨æ­¤å¤ä¹ ä½ çš„å•è¯åˆ—è¡¨ã€‚",
            article_type=article_type_code,
            words_json=[]
        )
    except Exception as e:
        print(f"Review Generation Error: {e}")
        return ReviewArticle(
            title="AI åˆ›ä½œæš‚æ—¶ä¼‘æ¯ä¸­",
            content=f"ç”±äºæŠ€æœ¯åŸå› æœªèƒ½ç”Ÿæˆæ–‡ç« ã€‚é”™è¯¯: {str(e)}",
            article_type="none",
            words_json=[]
        )

