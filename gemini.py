from google import genai
from google.genai import types
from pydantic import BaseModel, Field
from typing import List, Optional
import os
import json
import base64
from dotenv import load_dotenv
from schemas import (
    AnalysisResult, AnalysisRequest, ModelLevel,
    DictionaryResult, LookupRequest,
    WritingResult, WritingRequest, WritingMode,
    ChatRequest, TTSRequest, TTSResponse
)

try:
    load_dotenv()
except Exception as e:
    print(f"Warning: Could not load .env file: {e}")

api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    print("Warning: GEMINI_API_KEY not found in environment. AI features will fail.")
    api_key = "MISSING_API_KEY"

client = genai.Client(api_key=api_key)

# --- Existing Subtitle Logic ---
class SubtitleItem(BaseModel):
    start: str = Field(description="Original start timestamp string (e.g., '00:01:23.456'). Do NOT convert to seconds.")
    end: str = Field(description="Original end timestamp string (e.g., '00:01:25.789'). Do NOT convert to seconds.")
    text: str = Field(description="Complete, merged sentence text.")

class SubtitlesResponse(BaseModel):
    subtitles: List[SubtitleItem]

async def get_response(prompt):
    response = await client.aio.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt,
        config=types.GenerateContentConfig(
            response_mime_type="application/json",
            response_schema=SubtitlesResponse,
            thinking_config=types.ThinkingConfig(
                thinking_budget=0
            ),
            system_instruction="""
                    # Role
                    You are an expert subtitle editor. 
                    
                    # Task
                    1. Merge fragmented sentences into complete sentences based on context.
                    2. Deduplicate repeating lines.
                    3. Keep timestamps in their **ORIGINAL format** (HH:MM:SS.mmm).
                    
                    # Rules
                    - strictly maintain the timeline sequence.
                    - Start time = start timestamp of the first fragment.
                    - End time = end timestamp of the last fragment.
                    - Do NOT convert times to math/floats. Just copy the string.
            """),
    )
    return response.parsed.subtitles

# --- SmashEnglish Logic ---

def get_model_config(level: ModelLevel):
    if level == 'mini':
        return 'gemini-2.5-flash', 0
    elif level == 'quick':
        return 'gemini-2.5-flash', 500
    elif level == 'deep':
        return 'gemini-2.5-flash', 2000
    else:
        return 'gemini-2.5-flash', 0

async def analyze_sentence_service(sentence: str, model_level: ModelLevel) -> AnalysisResult:
    model, thinking_budget = get_model_config(model_level)
    
    prompt = f"""
    ‰Ω†ÊòØ‰∏Ä‰ΩçÁ≤æÈÄöËØ≠Ë®ÄÂ≠¶ÂíåËã±ËØ≠ÊïôÂ≠¶ÁöÑ‰∏ìÂÆ∂ AI„ÄÇËØ∑ÂàÜÊûê‰ª•‰∏ãËã±ËØ≠Âè•Â≠êÔºö "{sentence}"„ÄÇ
    ÁõÆÊ†áÂèó‰ºóÊòØÊ≠£Âú®Â≠¶‰π†Ëã±ËØ≠ÁöÑÂ≠¶ÁîüÔºåÂõ†Ê≠§ÂàÜÊûêÈúÄË¶Å**Ê∏ÖÊô∞„ÄÅÂáÜÁ°Æ‰∏îÂÖ∑ÊúâÊïôËÇ≤ÊÑè‰πâ**„ÄÇ

    **Processing Steps (Thinking Process):**
    1.  **Grammar Check (Á∫†Èîô)**: 
        - ‰ªîÁªÜÊ£ÄÊü•Âè•Â≠êÊòØÂê¶ÊúâËØ≠Ê≥ïÈîôËØØ„ÄÇ
        - Â¶ÇÊûúÊúâÈîôÔºåÂàõÂª∫‰∏Ä‰∏™‰øÆÊ≠£ÂêéÁöÑÁâàÊú¨„ÄÇ
        - **Ê≥®ÊÑè**ÔºöÂêéÁª≠ÁöÑÊâÄÊúâÂàÜÊûêÔºàchunks, detailedTokens, structureÔºâÂøÖÈ°ªÂü∫‰∫é**‰øÆÊ≠£Âêé(Corrected)** ÁöÑÂè•Â≠êËøõË°å„ÄÇ
        - **Diff Generation**: ÁîüÊàê 'changes' Êï∞ÁªÑÊó∂ÔºåÂøÖÈ°ªÊòØ‰∏•Ê†ºÁöÑÊñáÊú¨Â∑ÆÂºÇÂØπÊØî (diff)„ÄÇ
          - 'remove': ‰ªÖÂåÖÂê´Ë¢´Âà†Èô§ÁöÑÂéüÊñáÁâáÊÆµÔºå**ÁªùÂØπ‰∏çË¶Å**ÂåÖÂê´ "->" Á¨¶Âè∑Êàñ "change x to y" ËøôÊ†∑ÁöÑÊèèËø∞„ÄÇ‰æãÂ¶ÇÂéüÂè•ÊòØ "i go"Ôºå‰øÆÊ≠£‰∏∫ "I go"ÔºåÂàô 'remove' text ‰∏∫ "i"Ôºå'add' text ‰∏∫ "I"„ÄÇ
          - 'add': ‰ªÖÂåÖÂê´Êñ∞Âä†ÂÖ•ÁöÑÁâáÊÆµ„ÄÇ
          - 'keep': ‰øùÊåÅ‰∏çÂèòÁöÑÈÉ®ÂàÜ„ÄÇ

    2.  **Macro Analysis (ÂÆèËßÇÁªìÊûÑ)**:
        - ËØÜÂà´Ê†∏ÂøÉÂè•ÂûãÁªìÊûÑ (Pattern)Ôºå**ÂøÖÈ°ªÂåÖÂê´‰∏≠ÊñáÁøªËØë**„ÄÇÊ†ºÂºèË¶ÅÊ±ÇÔºö"English Pattern (‰∏≠ÊñáÂêçÁß∞)"„ÄÇ‰æãÂ¶ÇÔºö"S + V + O (‰∏ªË∞ìÂÆæ)"„ÄÇ
        - ËØÜÂà´Ê†∏ÂøÉÊó∂ÊÄÅ (Tense)Ôºå**ÂøÖÈ°ªÂåÖÂê´‰∏≠ÊñáÁøªËØë**„ÄÇÊ†ºÂºèË¶ÅÊ±ÇÔºö"English Tense (‰∏≠ÊñáÂêçÁß∞)"„ÄÇ‰æãÂ¶ÇÔºö"Present Simple (‰∏ÄËà¨Áé∞Âú®Êó∂)"„ÄÇ

    3.  **Chunking (ÂèØËßÜÂåñÊÑèÁæ§ÂàÜÂùó)**:
        - ÁõÆÊ†áÊòØÂ±ïÁ§∫Âè•Â≠êÁöÑ‚ÄúËäÇÂ•è‚ÄùÂíå‚ÄúÊÑèÁæ§‚Äù(Sense Groups)„ÄÇ
        - **ÂéüÂàô**Ôºö
          - ÊâÄÊúâÁöÑ‰øÆÈ•∞ËØ≠Â∫î‰∏éÂÖ∂‰∏≠ÂøÉËØçÂú®‰∏ÄËµ∑Ôºà‰æãÂ¶Ç "The very tall man" ÊòØ‰∏Ä‰∏™ÂùóÔºâ„ÄÇ
          - ‰ªãËØçÁü≠ËØ≠ÈÄöÂ∏∏‰Ωú‰∏∫‰∏Ä‰∏™Êï¥‰ΩìÔºà‰æãÂ¶Ç "in the morning" ÊòØ‰∏Ä‰∏™ÂùóÔºâ„ÄÇ
          - Ë∞ìËØ≠Âä®ËØçÈÉ®ÂàÜÂêàÂπ∂Ôºà‰æãÂ¶Ç "have been waiting" ÊòØ‰∏Ä‰∏™ÂùóÔºâ„ÄÇ
          - ‰∏çÂÆöÂºèÁü≠ËØ≠ÂêàÂπ∂Ôºà‰æãÂ¶Ç "to go home" ÊòØ‰∏Ä‰∏™ÂùóÔºâ„ÄÇ

    4.  **Detailed Analysis (ÈÄêËØç/Áü≠ËØ≠ËØ¶Ëß£)**:
        - **Ê†∏ÂøÉÂéüÂàô - Âõ∫ÂÆöÊê≠ÈÖç‰ºòÂÖà**Ôºö
          - ÈÅáÂà∞Áü≠ËØ≠Âä®ËØç (phrasal verbs)„ÄÅÂõ∫ÂÆö‰π†ËØ≠ (idioms)„ÄÅ‰ªãËØçÊê≠ÈÖç (collocations) Êó∂Ôºå**ÂøÖÈ°ª**Â∞ÜÂÆÉ‰ª¨‰Ωú‰∏∫‰∏Ä‰∏™Êï¥‰Ωì TokenÔºå**ÁªùÂØπ‰∏çË¶ÅÊãÜÂàÜ**„ÄÇ
          - ‰æãÂ¶ÇÔºö"look forward to", "take care of", "a cup of", "depend on"„ÄÇ
          - **ÁâπÂà´Â§ÑÁêÜÂèØÂàÜÁ¶ªÁü≠ËØ≠Âä®ËØç (Separable Phrasal Verbs)**Ôºö
            - Â¶ÇÊûúÈÅáÂà∞ÂÉè "pop us back", "turn it on" ËøôÊ†∑Âä®ËØç‰∏éÂ∞èÂìÅËØçË¢´‰ª£ËØçÈöîÂºÄÁöÑÊÉÖÂÜµÔºåËØ∑Âä°ÂøÖ**ËØÜÂà´Âá∫ÂÖ∂Ê†∏ÂøÉÁü≠ËØ≠Âä®ËØç**ÔºàÂ¶Ç "pop back"Ôºâ„ÄÇ
            - Âú®ËØ¶ÁªÜËß£Èáä (explanation) ‰∏≠Ôºå**ÂøÖÈ°ª**ÊòéÁ°ÆÊåáÂá∫ËØ•ËØçÂ±û‰∫éÁü≠ËØ≠Âä®ËØç "pop back" (ÊàñÁõ∏Â∫îÁü≠ËØ≠)ÔºåÂπ∂Ëß£ÈáäËØ•Áü≠ËØ≠Âä®ËØçÁöÑÂê´‰πâÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØÂçï‰∏™ÂçïËØçÁöÑÊÑèÊÄù„ÄÇ
            - Á§∫‰æãÔºöÈíàÂØπ "pop us back"ÔºåÂú®Ëß£Èáä "pop" Êó∂ÔºåÂ∫îËØ¥Êòé "pop ... back ÊòØÁü≠ËØ≠Âä®ËØçÔºåÊÑè‰∏∫ËøÖÈÄüÂõûÂéª/ÊîæÂõû"„ÄÇ
        - **Ëß£Èáä (Explanation)**Ôºö
          - ‰∏çË¶ÅÂè™Áªô‰∏Ä‰∏™ËØçÊÄßÊ†áÁ≠æ„ÄÇË¶ÅËß£ÈáäÂÆÉÂú®Âè•Â≠ê‰∏≠ÁöÑ**ÂäüËÉΩ**Âíå**‰∏∫‰ªÄ‰πàÁî®ËøôÁßçÂΩ¢Âºè**„ÄÇ
          - ‰æãÂ¶ÇÔºö‰∏çË¶ÅÂè™ÂÜô"ËøáÂéªÂàÜËØç"ÔºåË¶ÅÂÜô"ËøáÂéªÂàÜËØçÔºå‰∏é has ÊûÑÊàêÁé∞Âú®ÂÆåÊàêÊó∂ÔºåË°®Á§∫Âä®‰ΩúÂ∑≤ÂÆåÊàê"„ÄÇ
        - **Âê´‰πâ (Meaning)**ÔºöÊèê‰æõÂú®ÂΩìÂâçËØ≠Â¢É‰∏ãÁöÑ‰∏≠ÊñáÂê´‰πâ„ÄÇ

    ËØ∑ËøîÂõû JSON Ê†ºÂºèÊï∞ÊçÆ„ÄÇ
    """

    try:
        response = await client.aio.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=AnalysisResult,
                thinking_config=types.ThinkingConfig(thinking_budget=thinking_budget) if thinking_budget > 0 else None,
            )
        )
        
        if not response.parsed:
             raise ValueError("Empty response from Gemini")
             
        result = response.parsed
        # Match frontend logic: use corrected sentence if available
        if result.correction:
            result.englishSentence = result.correction.corrected
        else:
            result.englishSentence = sentence
            
        return result
    except Exception as e:
        print(f"Gemini API Error: {e}")
        raise Exception("Êó†Ê≥ïÂàÜÊûêËØ•Âè•Â≠ê„ÄÇËØ∑Ê£ÄÊü•ÁΩëÁªúÊàñ API Key ËÆæÁΩÆ„ÄÇ")


async def lookup_word_service(word: str, model_level: ModelLevel) -> DictionaryResult:
    model, thinking_budget = get_model_config(model_level)

    prompt = f"""
    Act as a professional learner's dictionary specifically tailored for students preparing for **IELTS, TOEFL, and CET-6**.
    User Look-up Query: "{word}".
    
    **STEP 1: Normalization & Generalization (CRITICAL)**
    1. Analyze the user's input. Is it a specific instance of a phrasal verb or collocation with specific pronouns?
    2. If yes, convert it to the **Canonical Form** (Headword).
       - Input: "pop us back" -> Output: "pop sth back"
       - Input: "made up my mind" -> Output: "make up one's mind"
    
    **STEP 2: Filtering & Content Generation**
    1. **Target Audience**: Students preparing for exams (IELTS, TOEFL, CET-6) and daily communication.
    2. **Filtering Rule**: 
       - OMIT rare, archaic, obsolete, or highly technical scientific definitions unless the word itself is technical.
       - Focus ONLY on the most common 3-4 meanings used in modern English and exams.
    3. **COCA Frequency per Part of Speech**:
       - For each part of speech (e.g. Noun vs Verb), estimate its specific COCA frequency rank.
       - Example: "address" might be "Rank 1029" as a Noun, but "Rank 1816" as a Verb.
       - Provide a concise string like "Rank 1029" or "Top 2000".

    **STEP 3: Structure**
    - Definitions: Clear, simple English explanation + Concise Chinese meaning.
    - Examples: Must be natural, modern, and relevant to exam contexts or daily life.
    
    **STEP 4: Collocations & Fixed Phrases**
    - Identify 3-5 high-frequency collocations, idioms, or fixed phrases containing this word.
    - Prioritize phrases useful for IELTS/TOEFL writing or speaking.
    - Provide meaning and a sentence example for each.

    Structure the response by Part of Speech (POS).
    Return strictly JSON.
    """

    try:
        response = await client.aio.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=DictionaryResult,
                thinking_config=types.ThinkingConfig(thinking_budget=thinking_budget) if thinking_budget > 0 else None,
            )
        )
        
        if not response.parsed:
             raise ValueError("Empty response from Gemini")
        
        return response.parsed
    except Exception as e:
        print(f"Dictionary API Error: {e}")
        raise Exception("Êó†Ê≥ïÊü•ËØ¢ËØ•ÂçïËØçÔºåËØ∑ÈáçËØï„ÄÇ")


async def evaluate_writing_service(text: str, mode: WritingMode, model_level: ModelLevel) -> WritingResult:
    model, thinking_budget = get_model_config(model_level)

    mode_instructions = ""
    if mode == 'fix':
        mode_instructions = """
        **MODE: BASIC CORRECTION (Âü∫Á°ÄÁ∫†Èîô)**
        - Target: General accuracy.
        - Task: Focus STRICTLY on correcting grammar, spelling, punctuation, and serious awkwardness.
        - Do NOT change style, tone, or vocabulary unless it is incorrect.
        - Keep the output very close to the original, only fixing errors.
        """
    elif mode == 'ielts-5.5':
        mode_instructions = """
        **MODE: IELTS BAND 5.5 (Modest User)**
        - Target Level: Partial command of the language.
        - Task: Correct all basic errors. Ensure the overall meaning is clear.
        - Style: Keep vocabulary simple but correct. Avoid complex structures if they risk error.
        - Feedback focus: Basic grammar and clarity.
        """
    elif mode == 'ielts-6.0':
        mode_instructions = """
        **MODE: IELTS BAND 6.0 (Competent User)**
        - Target Level: Generally effective command.
        - Task: Use a mix of simple and complex sentence forms. Correct errors.
        - Style: Use adequate vocabulary. Ensure coherence.
        """
    elif mode == 'ielts-6.5':
        mode_instructions = """
        **MODE: IELTS BAND 6.5 (Between Competent and Good)**
        - Target Level: Stronger competence.
        - Task: Introduce more complex structures. Enhance vocabulary slightly beyond basic.
        - Style: Improve flow and linking words.
        """
    elif mode == 'ielts-7.0':
        mode_instructions = """
        **MODE: IELTS BAND 7.0 (Good User)**
        - Target Level: Operational command, occasional inaccuracies.
        - Task: Use a variety of complex structures. Use less common lexical items.
        - Style: Academic and formal. Show awareness of style and collocation.
        """
    elif mode == 'ielts-7.5':
        mode_instructions = """
        **MODE: IELTS BAND 7.5 (Very Good User)**
        - Target Level: High accuracy.
        - Task: Sophisticated control of vocabulary and grammar. Minimize errors to very occasional slips.
        - Style: Highly polished, natural, and academic.
        """
    elif mode == 'ielts-8.0':
        mode_instructions = """
        **MODE: IELTS BAND 8.0 (Expert-like User)**
        - Target Level: Fully operational command.
        - Task: Use a wide range of vocabulary fluently and flexibly to convey precise meanings.
        - Style: Skillful use of uncommon lexical items. Error-free sentences. Native-like flow.
        """
    else:
        mode_instructions = "**MODE: BASIC CORRECTION**"

    prompt = f"""
    Act as a professional English Editor and IELTS Examiner.
    
    {mode_instructions}

    **Task**:
    Analyze the user's text and reconstruct it into the *Improved Version* according to the selected mode.
    You must return the result as a sequence of SEGMENTS that allow us to reconstruct the full text while highlighting exactly what changed.

    **Input Text**: "{text}"

    **Output Logic**:
    - Iterate through the improved text.
    - If a part of the text is the same as original, mark it as 'unchanged'.
    - If you changed, added, or removed something, create a segment of type 'change'.
      - 'text': The NEW/IMPROVED text.
      - 'original': The ORIGINAL text that was replaced (or empty string if added).
      - 'reason': A brief explanation in Chinese.
      - 'category': One of 'grammar', 'vocabulary', 'style', 'punctuation', 'collocation' | 'punctuation'.
    - **CRITICAL - PARAGRAPH PRESERVATION**: 
      - You MUST preserve all paragraph breaks and newlines (\\n) from the original text exactly as they are.
      - When you encounter a newline in the original text, return it as a separate segment: {{ "text": "\\n", "type": "unchanged" }}.
      - Do NOT merge paragraphs.
    
    **Example**:
    Original: "I go store.\\n\\nIt was fun."
    Improved: "I went to the store.\\n\\nIt was fun."
    Segments:
    [
      {{ "text": "I ", "type": "unchanged" }},
      {{ "text": "went", "original": "go", "type": "change", "reason": "Past tense", "category": "grammar" }},
      {{ "text": " to the ", "original": "", "type": "change", "reason": "Preposition", "category": "grammar" }},
      {{ "text": "store.", "type": "unchanged" }},
      {{ "text": "\\n\\n", "type": "unchanged" }},
      {{ "text": "It was fun.", "type": "unchanged" }}
    ]

    Return strictly JSON.
    """
    
    # Define a partial schema for response to match WritingResult structure but without 'mode' which we set manually
    class WritingResponseSchema(BaseModel):
        generalFeedback: str
        segments: List[WritingResult.model_fields['segments'].annotation]

    try:
        response = await client.aio.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=WritingResult, # Using the full WritingResult schema, hoping Gemini fills 'mode' or we override it
                thinking_config=types.ThinkingConfig(thinking_budget=thinking_budget) if thinking_budget > 0 else None,
            )
        )

        if not response.parsed:
            raise ValueError("Empty response")
            
        result = response.parsed
        # Ensure mode matches request
        result.mode = mode
        return result

    except Exception as e:
        print(f"Writing Evaluation API Error: {e}")
        raise Exception("ÂÜô‰ΩúÂàÜÊûêÂ§±Ë¥•ÔºåËØ∑Ê£ÄÊü•ÁΩëÁªúÊàñÁ®çÂêéÂÜçËØï„ÄÇ")


async def chat_service(request: ChatRequest) -> str:
    context_instruction = ""
    if request.contextType == 'sentence':
         context_instruction = f'**ÂΩìÂâçÊ≠£Âú®ÂàÜÊûêÁöÑÂè•Â≠ê**: "{request.contextContent or "Áî®Êà∑ÊöÇÊú™ËæìÂÖ•Âè•Â≠ê"}"„ÄÇ'
    elif request.contextType == 'word':
         context_instruction = f'**ÂΩìÂâçÊ≠£Âú®Êü•ËØ¢ÁöÑÂçïËØç/ËØçÁªÑ**: "{request.contextContent or "Áî®Êà∑ÊöÇÊú™Êü•ËØ¢ÂçïËØç"}"„ÄÇ'
    elif request.contextType == 'writing':
         context_instruction = f'**ÂΩìÂâçÊ≠£Âú®Ê∂¶Ëâ≤ÁöÑÊñáÁ´†**: "{request.contextContent or "Áî®Êà∑ÊöÇÊú™ËæìÂÖ•ÊñáÁ´†"}"„ÄÇ'

    system_instruction = f"""
        ‰Ω†ÊòØ‰∏Ä‰∏™ÁÉ≠ÊÉÖ„ÄÅ‰∏ì‰∏öÁöÑËã±ËØ≠Â≠¶‰π†Âä©Êïô„ÄÇ
        
        {context_instruction}
        
        **‰Ω†ÁöÑ‰ªªÂä°**Ôºö
        1. Ëß£Á≠îÁî®Êà∑ÂÖ≥‰∫éËã±ËØ≠ËØ≠Ê≥ï„ÄÅÂçïËØçÁî®Ê≥ï„ÄÅÂè•Â≠êÁªìÊûÑÊàñËØçÊ±áËæ®ÊûêÁöÑÈóÆÈ¢ò„ÄÇ
        2. **ÂßãÁªà‰ΩøÁî®‰∏≠Êñá**ÂõûÁ≠î„ÄÇ
        3. ‰ΩøÁî® **Markdown** Ê†ºÂºèÊù•ÁæéÂåñ‰Ω†ÁöÑÂõûÁ≠îÔºå‰ΩøÂÖ∂Ê∏ÖÊô∞ÊòìËØªÔºö
           - ‰ΩøÁî® **Âä†Á≤ó** Êù•Âº∫Ë∞ÉÈáçÁÇπÂçïËØçÊàñËØ≠Ê≥ïÊúØËØ≠„ÄÇ
           - ‰ΩøÁî®ÂàóË°®Ôºà1. Êàñ -ÔºâÊù•ÂàÜÁÇπËß£Èáä„ÄÇ
           - ÈÄÇÂΩìÂàÜÊÆµ„ÄÇ
        4. ËØ≠Ê∞îË¶ÅÈºìÂä±„ÄÅÁßØÊûÅÔºåÂÉè‰∏Ä‰ΩçËÄêÂøÉÁöÑËÄÅÂ∏à„ÄÇ
        5. **ÁâπÊÆäÊåá‰ª§**ÔºöÂ¶ÇÊûúÁî®Êà∑ËØ¢ÈóÆÁ±ª‰ºº "pop us back" ËøôÊ†∑ÁöÑÁü≠ËØ≠ÔºåËØ∑Ëß£ÈáäËøôÊòØ‰∏ÄÁßçÂè£ËØ≠Ë°®ËææÔºåÊ†∏ÂøÉÊòØÁü≠ËØ≠Âä®ËØç "pop back" (ËøÖÈÄüÂõûÂéª)Ôºå"us" ÊòØÂÆæËØ≠„ÄÇ
    """
    
    # Reconstruct history for Gemini
    # Gemini python SDK expects a slightly different history format if using chat.sendMessage
    # But here we might just do a single turn generation with history context if we want to be stateless, 
    # OR use the chat session. Given FastAPI is stateless, we should probably pass the history.
    # However, the `google.genai` SDK `chats.create` creates a session. 
    # We can manually construct the `contents` list from history + new message.
    
    contents = []
    for msg in request.history:
        # üî• ÂÖ≥ÈîÆ‰øÆÂ§çÔºöÂ∞Ü 'assistant' ËΩ¨Êç¢‰∏∫ Gemini ÊúüÊúõÁöÑ 'model'
        role = 'model' if msg.role == 'assistant' else msg.role
        contents.append(types.Content(role=role, parts=[types.Part(text=msg.content)]))
    
    # Add user's new message
    contents.append(types.Content(role='user', parts=[types.Part(text=request.userMessage)]))

    try:
        response = await client.aio.models.generate_content(
            model='gemini-2.5-flash',
            contents=contents,
            config=types.GenerateContentConfig(
                system_instruction=system_instruction
            )
        )
        return response.text
    except Exception as e:
        print(f"Chat API Error: {e}")
        raise Exception("ËÅäÂ§©ÊúçÂä°ÊöÇÊó∂‰∏çÂèØÁî®„ÄÇ")


async def generate_speech_service(text: str) -> str:
    try:
        # Use a model that supports audio generation (e.g., gemini-2.0-flash-exp)
        response = await client.aio.models.generate_content(
            model="gemini-2.5-flash-preview-tts",
            contents=text,
            config=types.GenerateContentConfig(
                response_modalities=['AUDIO'],
                speech_config=types.SpeechConfig(
                    voice_config=types.VoiceConfig(
                        prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name='Kore')
                    )
                )
            )
        )

        # Accessing audio data from response
        # The SDK returns binary data in candidates[0].content.parts[0].inline_data.data
        
        if not response.candidates or not response.candidates[0].content.parts:
             raise ValueError("No content returned")
             
        part = response.candidates[0].content.parts[0]
        if not part.inline_data or not part.inline_data.data:
             raise ValueError("No audio data returned")
             
        # inline_data.data is bytes. We need to return base64 string for JSON response.
        return base64.b64encode(part.inline_data.data).decode('utf-8')

    except Exception as e:
        print(f"TTS API Error: {e}")
        raise Exception("ËØ≠Èü≥ÁîüÊàêÂ§±Ë¥•„ÄÇ")
